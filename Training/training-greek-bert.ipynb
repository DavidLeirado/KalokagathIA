{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndf=pd.read_csv('../input/clean-greek-v1/training_df.csv', sep=\">\")","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:05:04.523649Z","iopub.execute_input":"2021-05-27T08:05:04.524072Z","iopub.status.idle":"2021-05-27T08:05:05.440865Z","shell.execute_reply.started":"2021-05-27T08:05:04.524032Z","shell.execute_reply":"2021-05-27T08:05:05.440028Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"I7_CBtECSBnk","outputId":"867845ec-bd78-44e6-dc4c-835c78981e8c","execution":{"iopub.status.busy":"2021-05-27T08:05:05.442492Z","iopub.execute_input":"2021-05-27T08:05:05.442827Z","iopub.status.idle":"2021-05-27T08:05:05.468453Z","shell.execute_reply.started":"2021-05-27T08:05:05.442793Z","shell.execute_reply":"2021-05-27T08:05:05.467688Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"      Autor         Obra Fragmento  \\\n0  Xenophon  Memorabilia     1.1.1   \n1  Xenophon  Memorabilia     1.1.2   \n2  Xenophon  Memorabilia     1.1.3   \n3  Xenophon  Memorabilia     1.1.4   \n4  Xenophon  Memorabilia     1.1.5   \n\n                                               Texto  \n0  πολλακις εθαυμασα τισι ποτε λογοις αθηναιους ε...  \n1  πρωτον μεν ουν, ως ουκ ενομιζεν ους η πολις νο...  \n2  δ᾽ ουδεν καινοτερον εισεφερε των αλλων, οσοι μ...  \n3  αλλ᾽ οι μεν πλειστοι φασιν υπο τε των ορνιθων ...  \n4  καιτοι τις ουκ αν ομολογησειεν αυτον βουλεσθαι...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Autor</th>\n      <th>Obra</th>\n      <th>Fragmento</th>\n      <th>Texto</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Xenophon</td>\n      <td>Memorabilia</td>\n      <td>1.1.1</td>\n      <td>πολλακις εθαυμασα τισι ποτε λογοις αθηναιους ε...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Xenophon</td>\n      <td>Memorabilia</td>\n      <td>1.1.2</td>\n      <td>πρωτον μεν ουν, ως ουκ ενομιζεν ους η πολις νο...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Xenophon</td>\n      <td>Memorabilia</td>\n      <td>1.1.3</td>\n      <td>δ᾽ ουδεν καινοτερον εισεφερε των αλλων, οσοι μ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Xenophon</td>\n      <td>Memorabilia</td>\n      <td>1.1.4</td>\n      <td>αλλ᾽ οι μεν πλειστοι φασιν υπο τε των ορνιθων ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Xenophon</td>\n      <td>Memorabilia</td>\n      <td>1.1.5</td>\n      <td>καιτοι τις ουκ αν ομολογησειεν αυτον βουλεσθαι...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:05:06.208640Z","iopub.execute_input":"2021-05-27T08:05:06.208985Z","iopub.status.idle":"2021-05-27T08:05:06.581986Z","shell.execute_reply.started":"2021-05-27T08:05:06.208955Z","shell.execute_reply":"2021-05-27T08:05:06.581205Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"         Autor       Obra Fragmento  \\\ncount   159847     159847    159847   \nunique      56        446     52717   \ntop      Homer  Histories         1   \nfreq     25314      20047      1132   \n\n                                                    Texto  \ncount                                              159833  \nunique                                             155924  \ntop     αλλως τε και τουτο το χωριον εν τω πολεμω δημε...  \nfreq                                                   33  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Autor</th>\n      <th>Obra</th>\n      <th>Fragmento</th>\n      <th>Texto</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>159847</td>\n      <td>159847</td>\n      <td>159847</td>\n      <td>159833</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>56</td>\n      <td>446</td>\n      <td>52717</td>\n      <td>155924</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Homer</td>\n      <td>Histories</td>\n      <td>1</td>\n      <td>αλλως τε και τουτο το χωριον εν τω πολεμω δημε...</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>25314</td>\n      <td>20047</td>\n      <td>1132</td>\n      <td>33</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"id":"sJERoY65SlQV","outputId":"de900574-4502-4f04-f932-b4e1974f158d","execution":{"iopub.status.busy":"2021-05-27T08:05:06.858496Z","iopub.execute_input":"2021-05-27T08:05:06.858830Z","iopub.status.idle":"2021-05-27T08:05:06.920518Z","shell.execute_reply.started":"2021-05-27T08:05:06.858800Z","shell.execute_reply":"2021-05-27T08:05:06.919462Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Autor         0\nObra          0\nFragmento     0\nTexto        14\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"id":"snxTFNoDTBeb","outputId":"febeb5e6-9716-40a4-c7f9-929311d388da","execution":{"iopub.status.busy":"2021-05-27T08:05:07.371020Z","iopub.execute_input":"2021-05-27T08:05:07.371354Z","iopub.status.idle":"2021-05-27T08:05:07.444955Z","shell.execute_reply.started":"2021-05-27T08:05:07.371324Z","shell.execute_reply":"2021-05-27T08:05:07.444070Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import unicodedata\nimport json\nimport wandb\n\nfrom tqdm import tqdm\nfrom ipywidgets import IntProgress\n\nfrom sklearn.preprocessing import LabelEncoder\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelWithLMHead, BertForSequenceClassification\nfrom torch.nn import functional as F\nfrom transformers import AdamW","metadata":{"id":"1G1urUTsmO3F","execution":{"iopub.status.busy":"2021-05-27T08:05:07.825308Z","iopub.execute_input":"2021-05-27T08:05:07.825630Z","iopub.status.idle":"2021-05-27T08:05:17.233493Z","shell.execute_reply.started":"2021-05-27T08:05:07.825600Z","shell.execute_reply":"2021-05-27T08:05:17.232605Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"autor_dict = {k:i for i, k in enumerate(df.Autor.unique())}\nprint(autor_dict)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:05:17.235122Z","iopub.execute_input":"2021-05-27T08:05:17.235434Z","iopub.status.idle":"2021-05-27T08:05:17.254102Z","shell.execute_reply.started":"2021-05-27T08:05:17.235398Z","shell.execute_reply":"2021-05-27T08:05:17.253089Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"{'Xenophon': 0, 'Pseudo-Xenophon': 1, 'Hyperides': 2, 'Lycurgus': 3, 'Eusebius of Caesarea': 4, 'Demosthenes': 5, 'Homer': 6, 'Sophocles': 7, 'Isocrates': 8, 'Aristophanes': 9, 'Theophrastus': 10, 'Julian the Emperor': 11, 'Herodotus': 12, 'Strabo': 13, 'Aeschines': 14, 'Pausanias': 15, 'Andocides': 16, 'Antiphon': 17, 'Dinarchus': 18, 'Arrian': 19, 'Callimachus': 20, 'Lysias': 21, 'Apollonius Rhodius': 22, 'Thucydides': 23, 'Philostratus the Athenian': 24, 'Aristotle': 25, 'John, of Damascus (attributed author)': 26, 'Aeschylus': 27, 'Theocritus': 28, 'Apollodorus': 29, 'Plutarch': 30, 'Euripides': 31, 'Polybius': 32, 'Athenaeus': 33, 'Aelian': 34, 'Dionysius of Halicarnassus': 35, 'Procopius': 36, 'Appian': 37, 'Hippocrates': 38, 'Plato': 39, 'Basil, Saint, Bishop of Caesarea': 40, 'Aeneas Tacticus': 41, 'Asclepiodotus': 42, 'Quintus Smyrnaeus': 43, 'Clement of Alexandria': 44, 'Nonnus of Panopolis': 45, 'Cassius Dio Cocceianus': 46, 'Longinus': 47, 'Marcus Aurelius': 48, 'Longus': 49, 'Demetrius of Phaleron (attributed author)': 50, 'Barnabas': 51, 'Dio Chrysostom': 52, 'Lucian': 53, 'Callistratus': 54, 'Philostratus The Athenian': 55}\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('labels_encoder.json', 'w') as f:\n    f.write(json.dumps(autor_dict))","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:05:17.256425Z","iopub.execute_input":"2021-05-27T08:05:17.256826Z","iopub.status.idle":"2021-05-27T08:05:17.262347Z","shell.execute_reply.started":"2021-05-27T08:05:17.256790Z","shell.execute_reply":"2021-05-27T08:05:17.261347Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"text_batch = df.Texto\ndf.labels = df.Autor.map(lambda x: autor_dict[x])","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:05:17.264367Z","iopub.execute_input":"2021-05-27T08:05:17.264789Z","iopub.status.idle":"2021-05-27T08:05:17.357705Z","shell.execute_reply.started":"2021-05-27T08:05:17.264752Z","shell.execute_reply":"2021-05-27T08:05:17.356277Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n  \n","output_type":"stream"}]},{"cell_type":"code","source":"df.labels","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:05:17.358946Z","iopub.execute_input":"2021-05-27T08:05:17.359262Z","iopub.status.idle":"2021-05-27T08:05:17.367687Z","shell.execute_reply.started":"2021-05-27T08:05:17.359229Z","shell.execute_reply":"2021-05-27T08:05:17.366600Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0          0\n1          0\n2          0\n3          0\n4          0\n          ..\n159842    44\n159843    44\n159844    44\n159845    44\n159846    44\nName: Autor, Length: 159833, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('nlpaueb/bert-base-greek-uncased-v1')\nmodel = BertForSequenceClassification.from_pretrained('nlpaueb/bert-base-greek-uncased-v1',\n                                                      num_labels=len(autor_dict)).to('cuda')","metadata":{"id":"qCrPVGJLpecv","outputId":"22cbd951-ba62-4dce-c470-9b221b87a73e","execution":{"iopub.status.busy":"2021-05-27T08:05:53.676073Z","iopub.execute_input":"2021-05-27T08:05:53.676407Z","iopub.status.idle":"2021-05-27T08:06:06.244649Z","shell.execute_reply.started":"2021-05-27T08:05:53.676375Z","shell.execute_reply":"2021-05-27T08:06:06.243459Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at nlpaueb/bert-base-greek-uncased-v1 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/bert-base-greek-uncased-v1 and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"df.Autor.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:06:06.249037Z","iopub.execute_input":"2021-05-27T08:06:06.249380Z","iopub.status.idle":"2021-05-27T08:06:06.304129Z","shell.execute_reply.started":"2021-05-27T08:06:06.249346Z","shell.execute_reply":"2021-05-27T08:06:06.303072Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Homer                                        25314\nEuripides                                    16591\nAristophanes                                 12504\nPolybius                                     12140\nSophocles                                     9250\nProcopius                                     8258\nCassius Dio Cocceianus                        7128\nAeschylus                                     6731\nApollonius Rhodius                            5384\nHerodotus                                     4329\nDemosthenes                                   4277\nDionysius of Halicarnassus                    4258\nThucydides                                    3576\nEusebius of Caesarea                          3383\nPausanias                                     3170\nTheophrastus                                  2658\nHippocrates                                   2623\nDio Chrysostom                                2570\nAristotle                                     2464\nPlutarch                                      2166\nPlato                                         2136\nXenophon                                      2081\nArrian                                        1765\nLysias                                        1737\nStrabo                                        1579\nLucian                                        1569\nAthenaeus                                     1327\nAppian                                        1321\nAelian                                         802\nIsocrates                                      651\nAeschines                                      642\nMarcus Aurelius                                560\nLongus                                         537\nBasil, Saint, Bishop of Caesarea               463\nApollodorus                                    386\nAeneas Tacticus                                375\nJulian the Emperor                             369\nJohn, of Damascus (attributed author)          364\nPhilostratus the Athenian                      348\nDemetrius of Phaleron (attributed author)      304\nAndocides                                      269\nClement of Alexandria                          240\nHyperides                                      202\nBarnabas                                       194\nAntiphon                                       155\nLycurgus                                       150\nDinarchus                                      138\nAsclepiodotus                                   73\nCallimachus                                     61\nPhilostratus The Athenian                       58\nPseudo-Xenophon                                 53\nNonnus of Panopolis                             48\nLonginus                                        44\nTheocritus                                      30\nQuintus Smyrnaeus                               14\nCallistratus                                    14\nName: Autor, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(df.Texto, df.labels, test_size=.2, stratify=df.labels)\n\ntrain_texts = list(train_texts)\nval_texts = list(val_texts)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:06:06.308940Z","iopub.execute_input":"2021-05-27T08:06:06.309262Z","iopub.status.idle":"2021-05-27T08:06:06.544575Z","shell.execute_reply.started":"2021-05-27T08:06:06.309229Z","shell.execute_reply":"2021-05-27T08:06:06.543695Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:06:06.546192Z","iopub.execute_input":"2021-05-27T08:06:06.546521Z","iopub.status.idle":"2021-05-27T08:07:08.523001Z","shell.execute_reply.started":"2021-05-27T08:06:06.546486Z","shell.execute_reply":"2021-05-27T08:07:08.522119Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass GreekDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = list(labels)\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:07:08.524414Z","iopub.execute_input":"2021-05-27T08:07:08.524769Z","iopub.status.idle":"2021-05-27T08:07:08.532373Z","shell.execute_reply.started":"2021-05-27T08:07:08.524720Z","shell.execute_reply":"2021-05-27T08:07:08.531214Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_dataset = GreekDataset(train_encodings, train_labels)\nval_dataset = GreekDataset(val_encodings, val_labels)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:07:08.533822Z","iopub.execute_input":"2021-05-27T08:07:08.534185Z","iopub.status.idle":"2021-05-27T08:07:08.567378Z","shell.execute_reply.started":"2021-05-27T08:07:08.534149Z","shell.execute_reply":"2021-05-27T08:07:08.566522Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:07:08.568593Z","iopub.execute_input":"2021-05-27T08:07:08.569048Z","iopub.status.idle":"2021-05-27T08:07:08.616888Z","shell.execute_reply.started":"2021-05-27T08:07:08.569019Z","shell.execute_reply":"2021-05-27T08:07:08.616155Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results-stratified',          # output directory\n    num_train_epochs=2,              # total number of training epochs\n    per_device_train_batch_size=16,  # batch size per device during training\n    per_device_eval_batch_size=64,   # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=100,\n    evaluation_strategy='steps',\n    eval_steps=3000,\n    save_steps=3000\n)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:07:08.618934Z","iopub.execute_input":"2021-05-27T08:07:08.619276Z","iopub.status.idle":"2021-05-27T08:07:08.625587Z","shell.execute_reply.started":"2021-05-27T08:07:08.619243Z","shell.execute_reply":"2021-05-27T08:07:08.624591Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"val_labels","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:07:08.627256Z","iopub.execute_input":"2021-05-27T08:07:08.627610Z","iopub.status.idle":"2021-05-27T08:07:08.637411Z","shell.execute_reply.started":"2021-05-27T08:07:08.627566Z","shell.execute_reply":"2021-05-27T08:07:08.636624Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"61611     13\n86010     27\n113283    32\n10221      6\n135034    39\n          ..\n133555    36\n118762    32\n149988    25\n28835      6\n108594    32\nName: Autor, Length: 31967, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"wandb.login()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:07:08.638712Z","iopub.execute_input":"2021-05-27T08:07:08.639188Z","iopub.status.idle":"2021-05-27T08:07:23.817446Z","shell.execute_reply.started":"2021-05-27T08:07:08.639153Z","shell.execute_reply":"2021-05-27T08:07:23.816567Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,                         # the instantiated 🤗 Transformers model to be trained\n    args=training_args,                  # training arguments, defined above\n    train_dataset=train_dataset,         # training dataset\n    eval_dataset=val_dataset             # evaluation dataset\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:07:23.820341Z","iopub.execute_input":"2021-05-27T08:07:23.820614Z","iopub.status.idle":"2021-05-27T13:20:03.650002Z","shell.execute_reply.started":"2021-05-27T08:07:23.820587Z","shell.execute_reply":"2021-05-27T13:20:03.649187Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdleirado\u001b[0m (use `wandb login --relogin` to force relogin)\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                Tracking run with wandb version 0.10.26<br/>\n                Syncing run <strong style=\"color:#cdcd00\">./results-stratified</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/dleirado/huggingface\" target=\"_blank\">https://wandb.ai/dleirado/huggingface</a><br/>\n                Run page: <a href=\"https://wandb.ai/dleirado/huggingface/runs/16t48169\" target=\"_blank\">https://wandb.ai/dleirado/huggingface/runs/16t48169</a><br/>\n                Run data is saved locally in <code>/kaggle/working/wandb/run-20210527_080729-16t48169</code><br/><br/>\n            "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='15984' max='15984' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [15984/15984 5:12:19, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Runtime</th>\n      <th>Samples Per Second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>3000</td>\n      <td>0.936900</td>\n      <td>0.880408</td>\n      <td>545.240600</td>\n      <td>58.629000</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.758800</td>\n      <td>0.694633</td>\n      <td>544.927500</td>\n      <td>58.663000</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.509600</td>\n      <td>0.608101</td>\n      <td>544.824700</td>\n      <td>58.674000</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.480600</td>\n      <td>0.574660</td>\n      <td>544.861900</td>\n      <td>58.670000</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.403300</td>\n      <td>0.522690</td>\n      <td>544.875200</td>\n      <td>58.668000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=15984, training_loss=0.7255179240061594, metrics={'train_runtime': 18751.3076, 'train_samples_per_second': 0.852, 'total_flos': 8.874582216700723e+16, 'epoch': 2.0, 'init_mem_cpu_alloc_delta': 0, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': -356102144, 'train_mem_gpu_alloc_delta': 1362513408, 'train_mem_cpu_peaked_delta': 356294656, 'train_mem_gpu_peaked_delta': 12996649984})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model('modelo_final')","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:20:03.653290Z","iopub.execute_input":"2021-05-27T13:20:03.653646Z","iopub.status.idle":"2021-05-27T13:20:05.110847Z","shell.execute_reply.started":"2021-05-27T13:20:03.653607Z","shell.execute_reply":"2021-05-27T13:20:05.096096Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}