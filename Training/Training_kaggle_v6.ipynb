{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndf=pd.read_csv('../input/textos-griegoscsv/textos_griegos.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()\ndf.describe()","metadata":{"id":"I7_CBtECSBnk","outputId":"867845ec-bd78-44e6-dc4c-835c78981e8c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"id":"sJERoY65SlQV","outputId":"de900574-4502-4f04-f932-b4e1974f158d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"id":"snxTFNoDTBeb","outputId":"febeb5e6-9716-40a4-c7f9-929311d388da","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sustituirchars(linea):\n    return linea.replace('.',',').replace(',,','.')","metadata":{"id":"xFMJO64saE0V","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"id":"vYrk6-sUbRpv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autores_more_than = df.Autor.value_counts()[df.Autor.value_counts() > 10].index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autores_more_than","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.loc[df.Autor.isin(autores_more_than)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Texto=df.Texto.apply(lambda x: sustituirchars(x))","metadata":{"id":"nUSfYJtrakbL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"EM7aryxtbc5E","outputId":"4d37cc1c-7be6-44ac-f57a-c41847dd4c23","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import unicodedata\n\nfrom tqdm import tqdm\nfrom ipywidgets import IntProgress\n\nfrom sklearn.preprocessing import LabelEncoder\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelWithLMHead, BertForSequenceClassification\nfrom torch.nn import functional as F\nfrom transformers import AdamW","metadata":{"id":"1G1urUTsmO3F","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def strip_accents_and_lowercase(s):\n    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn').lower()","metadata":{"id":"kg5Asx3XnJN7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Texto = df.Texto.apply(lambda x: strip_accents_and_lowercase(x))","metadata":{"id":"N0ZxXi6joxHt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_batch = df.Texto\nlabels = LabelEncoder().fit_transform(df['Autor'])\ndf['labels']=labels","metadata":{"id":"2xaqTmaZpQQ-","outputId":"b6952c35-c50e-47f1-fc09-875deb0ce891","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('nlpaueb/bert-base-greek-uncased-v1')\nmodel = BertForSequenceClassification.from_pretrained('nlpaueb/bert-base-greek-uncased-v1',\n                                                      num_labels=len(np.unique(labels))).to('cuda')","metadata":{"id":"qCrPVGJLpecv","outputId":"22cbd951-ba62-4dce-c470-9b221b87a73e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Autor.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(df.Texto, df.labels, test_size=.2, stratify=df.labels)\n\ntrain_texts = list(train_texts)\nval_texts = list(val_texts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass GreekDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = list(labels)\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = GreekDataset(train_encodings, train_labels)\nval_dataset = GreekDataset(val_encodings, val_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results-stratified',          # output directory\n    num_train_epochs=2,              # total number of training epochs\n    per_device_train_batch_size=16,  # batch size per device during training\n    per_device_eval_batch_size=64,   # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=100,\n    evaluation_strategy='steps',\n    eval_steps=3000,\n    save_steps=3000\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n    args=training_args,                  # training arguments, defined above\n    train_dataset=train_dataset,         # training dataset\n    eval_dataset=val_dataset             # evaluation dataset\n)\n\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model('modelo_final')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}