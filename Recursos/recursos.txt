Modelo BERT para griego y c√≥mo funciona:

https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1
https://github.com/nlpaueb/greek-bert
https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification
https://www.youtube.com/watch?v=iDulhoQ2pro
https://www.youtube.com/watch?v=-9evrZnBorM


Ilustrated BERT, ilustrated transformer:

https://jalammar.github.io/illustrated-bert/
https://jalammar.github.io/illustrated-transformer/


Preprocesado del texto para introducir en el modelo:

https://huggingface.co/transformers/preprocessing.html


Para entender tokenizadores:

https://blog.floydhub.com/tokenization-nlp/
https://www.youtube.com/watch?v=zjaRNfvNMTs


Para analizar resultados:

https://medium.com/analytics-vidhya/explainability-of-bert-through-attention-7dbbab8a7062